---
layout: post
title: wip
date: 2022-01-01
tags: 
categories: 
author: berrysleaf
---
* content
{:toc}


## 期望风险 
在机器学习问题中，我们通常会定义一个损失函数，比如 $$L(y, f(x)) = (f(x)-y)^2$$ 用于度量假设的模型 $$f(x)$$ 与真实模型的距离。 这个损失函数（误差）的期望，称为**期望风险**。学习的目标就是期望风险最小化，即 




$$\text{min}_{f\in F} \mathbb{E}_{x,y\sim P_{data}}[L(y, f(x))]$$

其中 $$F$$ 是假设空间，$$P_{data}$$ 是数据分布。 问题在于，我们无法直接计算期望，因此需要通过采样来近似。而通过采样来近似的方法，称为**经验风险最小化**。采样得到的风险，称为**经验风险**。

**结构风险最小化**，是经验风险最小化的一个变种，它在经验风险的基础上，加入了模型复杂度的惩罚项。由于样本数量有限，模型复杂度的惩罚项，可以防止过拟合。

$$\text{min}_{f\in F} \mathbb{E}_{x,y\sim P_{data}}[L(y, f(x))] + \lambda J(f)$$

## 最大似然估计 
最大似然估计是一种用于估计参数的方法。这种估计方法代表了频率派的观点，即参数的真实值是客观存在的，只是未知而已。最大似然估计的基本思想是，通过观测数据，来估计参数的真实值，使得观测数据出现的概率最大。

假设我们观察的变量是 $$x$$，观察到的取值是 $$x_1, x_2, \cdots, x_n$$。我们假设 $$x$$ 的分布服从某个概率分布 $$P(x \vert \theta)$$，并且 $$x$$ 的取值是独立同分布的。那么，最大似然函数即是 $$\theta$$ 的一个估计值，它使得事件发生的可能性最大，即 

$$\theta_{ML} = \arg\max_{\theta} P(x_1, x_2, \cdots, x_n \vert \theta) = \arg\max_{\theta}P(x_1 \vert \theta) \cdots P(x_n\vert\theta)$$

求解以上问题的方法有多种，比如梯度下降法，牛顿法等。但是，这些方法都需要求解 $$\theta$$ 的导数，而导数的计算通常是很困难的。因此，我们可以采用一种近似的方法，即**拟牛顿法**。拟牛顿法的基本思想是，通过拟合一个二次函数，来近似求解 $$\theta$$ 的导数。这个二次函数的系数，可以通过梯度下降法来求解。

这个 $$\theta$$ 是一个固定的值，它能很好的拟合样本数据，但不一定拟合未知数据（过拟合）。 因此，用频率派的理论可以得出很多扭曲事实的结果，例如，只要我们没有观察到一种情况，那么这种情况就不会发生。

以抛硬币为例，一枚质地均匀的硬币连续 10 次都是正面，那么抛一次硬币获得反面的概率是多少呢？如果我们用频率派的理论，那么这个概率是 0。但是，这是不合理的。 

反之，贝叶斯学派的观点是，参数 $$\theta$$ 不是一个固定值，而是一个随机变量，也即是尽管我们没有直接观察到某个事件，但事件还是有一定的概率发生的。 


## 贝叶斯估计
正因为参数不固定，当给定一个输入 $$x$$ 时，我们只能一个概率的方式表达出 $$y$$ 的取值。因此，我们需要知道所有 $$\theta$$ 在获得观察数据 $$x$$ 的分布情况，即是后验概率 $$P(\theta \vert x)$$。这个后验概率可以通过贝叶斯公式来求解： 

$$P(\theta \vert x) = \frac{P(x \vert \theta)P(\theta)}{P(x)}$$

考虑 $$p(x)$$ 与最优 $$\theta$$ 无关，因此，我们可以忽略 $$p(x)$$，即 $$\theta_{MAP} = \arg\max_{\theta} P(x \vert \theta)P(\theta)$$。这即是最大后验估计，与最大似然估计相比，它多了一项先验概率 $$P(\theta)$$，这正好体现了贝叶斯认为参数也是随机变量的观点。 这个先验概率可以通过经验来估计，也可以通过其他的方式来估计。 

**最大似然估计其实是经验网络最小化的一个特例，而最大后验估计是结构风险最小化的一个例子。**



## 后验分布 
Posterior distributions.

根据样本 $$X$$ 的分布 $$P(\theta)$$ 及 $$\theta$$ 的先验分布 $$\pi(\theta)$$，用概率论中求条件概率分布的方法,可算出在已知$$X=x$$ 的条件下，$$\theta$$ 的条件分布 $$\pi(\theta|x)$$。因为这个分布是在抽样以后才得到的，故称为后验分布。


贝叶斯学派认为：这个后验分布综合了样本 $$x$$ 及先验分布 $$\pi(\theta)$$ 所提供的有关的信息。抽样的全部目的，就在于**完成由先验分布到后验分布的转换**([source](https://baike.baidu.com/item/%E5%90%8E%E9%AA%8C%E5%88%86%E5%B8%83/2022914#:~:text=%E6%A0%B9%E6%8D%AE%E6%A0%B7%E6%9C%ACX%20%E7%9A%84%E5%88%86%E5%B8%83,%E7%A7%B0%E4%B8%BA%E5%90%8E%E9%AA%8C%E5%88%86%E5%B8%83%E3%80%82))。



## 熵 

熵度量了事物的不确定性，越不确定的事物，它的熵就越大。具体的，随机变量 $$X$$ 的熵的表达式如下：

$$H(X) = -\sum\limits_{i=1}^{n}p_i \log {p_i}$$

其中 $$n$$ 代表 $$X$$ 的 $$n$$ 种不同的离散取值。而$$p_i$$代表了 $$X$$ 取值为 $$i$$ 的概率。

对应的，多个随机变量的联合熵定义为：

$$H(X,..., Y) = -\sum\limits_{x_i \in X} \cdots \sum\limits_{y_p \in Y}p(x_i,\cdots, y_p)\log{p(x_i,\cdots, y_p)}$$

条件熵的定义为:

$$H(Y|X) = -\sum\limits_{x_i \in X}\sum\limits_{y_j \in Y}p(x_i, y_j)\log{p(y_j|x_i)} = \sum\limits_{j=1}^{n}p(x_j)H(Y|x_j) $$


- 最大熵原理认为，学习概率模型时，在所有可能的概率模型分布中，熵最大的模型是最好的模型。通常用约束条件来确定概率模型的集合，所以，最大熵原理也可以表述为在满足约束条件的模型集合中选取熵最大的模型。


参考
- [最大熵原理小结](https://www.cnblogs.com/pinard/p/6093948.html)


# 对比学习 
对比学习（Contrastive Learning, CL）是近年来 AI 领域的热门研究方向，吸引了众多研究学者的关注，其所属的自监督学习方式，更是在 ICLR 2020 被 Bengio 和 LeCun 等大佬点名称为 AI 的未来，后陆续登陆 NIPS, ACL, KDD, CIKM 等各大顶会，Google, Facebook, DeepMind，阿里、腾讯、字节等大厂也纷纷对其投入精力，CL 的相关工作也是刷爆了 CV，乃至 NLP 部分问题的 SOTA，在 AI 圈的风头可谓一时无两。

CL 的技术源泉来自度量学习（metric learning），思想是：定义好样本的正例和负例，以及映射关系（将实体映射到新的空间），优化目标是让正例在空间中与目标样本的距离近一些，而负例要相对远一些。正因为如此，CL 看上去跟向量化召回思路很像，但其实二者有本质的区别，向量化召回属于监督学习的一种，会有明确的标签数据，而且更注重的负样本的选择（素有负样本为王的“学说”）；而 CL 是自监督学习（属于无监督学习的一种范式）的一支，不需要人工标注的标签信息，直接利用数据本身作为监督信息，学习样本数据的特征表达，进而引用于下游任务。此外，CL 的核心技术是数据增强（Data Augmentation），更加注重的是如何构造正样本。

谈到 CL 的原理，不得不提自监督学习，它避开了人工标注的高成本，以及**标签低覆盖的稀疏性**，更容易学到通用的特征表示。自监督学习可以分成两大类：**生成式方法和对比式方法**。生成式方法的典型代表是**自编码器**，而对比式学习的经典代表即 ICLR 2020 的 SimCLR，通过（增强后的）正负样本在特征空间的对比学习特征表示。相比较生成式方法，对比式方法的优势在于**无需对样本进行像素级的重构，只需要在特征空间能够学到可区分性即可**，这使得相关的优化变得简单。笔者认为，CL 的有效性主要体现在学习 item 表示的可区分性，而可区分性的学习依赖正负样本的构造思路，以及具体的模型结构和优化目标。


结合 CL 的实现过程，[张俊林博士](https://mp.weixin.qq.com/s/2Js8-YwUEa1Hr_ZYx3bF_A)抽象了三个 CL 必须要回答的问题，也是其区别于度量学习的典型特征，即
1. 如何构造正例和负例，也就是数据增强具体是如何实现的；
2. Encoder 映射函数如何构造，不仅要尽可能多地保留原始信息，而且要防止坍塌问题；
3. 损失函数如何设计，目前通常使用的 NCE loss，$$L_i=−\log(\exp(S(z_i,z_i^+)/\tau)/\sum_{j=0}^K \exp(S(z_i,z_j)/\tau))$$ 
   
不难看出，这三个基本问题对应建模的三要素：样本，模型，优化算法。从 loss 公式中可以看出，分子部分强调的是与正例的距离越近越好，S 函数衡量的是相似性，距离越近对应的 S 值越大，分母强调的是与负例的距离越远越好，loss 越低，对应的可区分性越高。

对比学习在文本表示中的应用可参考 [contrast learning]({{site.baseurl}}/2022/11/28/Contrast-Learning/)

参考： 
- [对比学习算法在转转的实践](https://juejin.cn/post/7158416789817262094)


## 对比学习的衡量指标
<img src="https://file.ddot.cc/imagehost/2022/alignment_uniformity.png">

主要指标有两个：alignment 和 uniformity。 Alignment 衡量的是正负样本的相似性，uniformity 衡量的是正负样本的分布是否均匀。

- Alignment：计算所有正样本对之间的距离，如果 alignment 越小，则正样本的向量越接近，对比学习效果越好，计算公式如下:
  $$\mathcal{l}_{\text{align}} = \mathbb{E}_{(x, x^+) \sim p_{pos}}  \Vert f(x) - f(x^+) \Vert^2$$
- uniformity 表示所有句子向量分布的均匀程度，越小表示向量分布越均匀，对比学习效果越好，计算公式如下：
  $$\mathcal{l}_{\text{uniform}} = \log \mathbb{E}_{(x, y) \sim^{i.i.d.} p_\text{data}} e^{-2 \Vert f(x)-f(y) \Vert^2}$$

其中 $$p_{\text{data}}$$ 表示数据分布。这两个指标与对比学习的目标是一致的：正例之间学到的特征应该是相近的，而任意向量的语
义特征应该尽可能地分散在超球体上。

Alignment 代表我们希望对比学习把相似的正例在投影空间里面有相近的编码，一般我们做一个 embedding 映射系统，都是希望达成此目标。 Uniformity 直观上来说就是：当所有实例映射到投影空间之后，我们希望它在投影空间内的分布是尽可能均匀的。求分布均匀性不是 uniformity 的目的，而是手段。追求分布的 uniformity 实际想达成的是:我们希望实例映射到投影空间后，在对应的embedding 包含的信息里，可以更多保留自己个性化的与众不同的信息。这样，我们在做分类任务的时候，就可以更好地区分不同的类别。


## 模型坍塌 
什么是模型坍塌（model collapse)？就是说不论你输入的是什么样本，经过映射函数之后，在投影空间里面，所有样本的编码都会坍塌到同一个点。坍塌到同一个点也即是不论我的输入是什么，最终经过函数映射，被映射成同一个 embedding，所有样本对应的 embedding 都是一样的，这意味映射函数没有编码任何有用的信息，这是一个很致命的问题。

如何避免模型坍塌，是做对比学习非常关键的一个问题。SimCLR 通过 InfoNCE 和负例来防止坍塌：通过正例来保证 alignment 原则，正例相似度越高，在单位超球面中距离越近；通过负例实现均匀 uniformity，在单位超球面之中负例之间互斥，距离越远越好，由此实现防止坍塌。所以，SimCLR 是通过负例来解决模型坍塌的，这是一种典型做法。目前得到的一个共识是：负例越多，学习效果越好。


# Python 
如何将同步代码改成异步，通过 `loop.run_in_executor(executor, func, *args)` ，比如：
```python
import asyncio
from time import sleep

async def sleep_async(loop, delay):
    # None uses the default executor (ThreadPoolExecutor)
    await loop.run_in_executor(None, sleep, delay)
    return 'I slept asynchronously'
```
除此之外，还有一些第三库，比如 [Asyncer](asyncer.tiangolo.com/), awaitable, aioify


# bash 
记一个最终没有解决的问题。 

一个小的项目：通过 Python 脚本监控 TP 的电池电量，当电池充满时，通过播放音频控制小爱音箱把插座关闭。音频播放使用了 `play`, `ffplay` 等工具。一个小问题是，如果直接运行脚本，则声音能够正常播放且效果符合预期，但如果通过 crontab 定时执行脚本，或者使用 supervisord 守护脚本，都无法播放音频。

类似的问题之前在通过脚本自动锁定、解锁 Linux 桌面的项目里也遇到过。

