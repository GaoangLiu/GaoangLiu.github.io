---
layout:     draft
title:      Prompt Engineering
date:       2024-01-01
categories: 
- nlp
---


提示工程（Prompt Engineering,PE），也称为上下文提示（In-Context Prompting ），是指在不更新模型权重的情况下，如何与 LLM 进行通信以引导其产生期望结果的方法。PE 是一门经验科学，提示工程方法的效果在模型之间可能差异很大，因此需要大量的实验和启发式方法。

# 基础提示

零样本学习和小样本学习是提示模型的两种最基本方法，方法简单直观，常用于评估LLM性能。
顾名思义，零样本学习就是直接把任务文本输入模型，并要求它返回对应的结果。这非常考验模型的综合理解与推理能力。 

```text
Input: 姜还是老的辣呀，影片结束大概鼓掌也就鼓了25分钟这样吧，tim cook也来了现场，感觉很亲切，有点把戛纳影厅变成了apple tv+的发布会的气质。
Sentiment:
```

有时候，问题稍微复杂时，比如 24 点游戏（参考之前博客[《tree of thoughts》]({{site.baseurl}}/2023/12/10/Tree-of-Thoughts/)中聊到的示例）， 零样本学习的效果就不好了。这时候，我们可以使用小样本学习，即给模型提供一些样本，让它学习到一些规律，然后再进行预测。

```text
Input: 给定 4 张牌，每张牌上的数字分别为 4,5,6,9，你可以任意使用加减乘除，使得最后的结果为 24，给出一种解法。
Output: 4 + 5 + 6 + 9 = 24

Input: 给定 4 张牌，每张牌上的数字分别为 1,3,5,7，你可以任意使用加减乘除，使得最后的结果为 24，给出一种解法。
Output: (3-1)*(7+5)=24

Input: 给定 4 张牌，每张牌上的数字分别为 4,8,7,12，你可以任意使用加减乘除，使得最后的结果为 24，给出一种解法。
Output: 没有解法
```

小样本学习提供了一组高质量的示例，每个示例都包含输入和目标任务的预期输出。模型通过这些示例，去理解人类意图以及对要生成的答案的标准。小样本学习效果通常比零样本学习更好。但代价是需要消耗更多的 tokens，且当输入和输出文本都很长时，可能会达到上下文长度限制。

# 指令微调 
在小样本学习的 prompt 中，举例子的目的是为了让模型更好的理解我们的意图，然后以照葫芦画瓢的方式去解决任务。但小样本学习有两个缺点：一是消耗更多的 tokens，二是增加了输入输出的长度。那一种想法，我们能不能告诉模型我们要做什么，然后让模型自己去解决任务呢？答案是肯定的，这就是指令微调（Instruction Fine-tuning,IF）。

