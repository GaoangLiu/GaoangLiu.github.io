{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does `criterion=gini/entropy` make any difference in Decision Tree ?\n",
    "Gini or Entropy references:\n",
    "1. ref 1: https://datascience.stackexchange.com/questions/10228/when-should-i-use-gini-impurity-as-opposed-to-information-gain\n",
    "2. ref 2: https://www.quora.com/What-is-difference-between-Gini-Impurity-and-Entropy-in-Decision-Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method: \n",
    "* Generate random datasets, with:\n",
    "    1. n_f: feature number between 5 to 20\n",
    "    2. n_i: informative 1 to n_f\n",
    "    3. n_r: n_redundant 0 to (n_f - n_i)\n",
    "    4. n_c: n classes between 1 to n_i\n",
    "\n",
    "* Run classifiers with criterion 'gini' and 'entropy' respectively, return accuracy score\n",
    "\n",
    "* Draw accuracy score graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy accuracy score 0.815\n",
      "entropy accuracy score 0.84\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.815, 0.84)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def generate_data():\n",
    "    '''Random choose:\n",
    "    1. n_f: feature number between 5 to 20\n",
    "    2. n_i: informative 1 to n_f\n",
    "    3. n_r: n_redundant 0 to (n_f - n_i)\n",
    "    4. n_c: n classes between 1 to 10\n",
    "    '''\n",
    "    n_f = random.randint(5, 20)\n",
    "    n_i = random.randint(1, n_f)\n",
    "    n_r = random.randint(1, n_f - n_i)\n",
    "    n_c = random.randint(1, n_i)\n",
    "\n",
    "    X, y = make_classification(n_samples=1000, n_features=n_f, n_informative=n_i,\n",
    "                               n_redundant=n_r, n_classes=n_c,\n",
    "                               n_clusters_per_class=1, random_state=0)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def expe_accuracy():\n",
    "    ''' Generate random dataset with classification, test with 'gini' & 'entropy', \n",
    "    return accruacy score\n",
    "    '''\n",
    "    X, y = generate_data()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0, test_size=0.2)\n",
    "    \n",
    "    # tree max_depth\n",
    "    max_depth = random.randint(1, 30)\n",
    "\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth, criterion='gini')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_preds = clf.predict(X_val)\n",
    "    acc_gini = accuracy_score(y_val, y_preds)\n",
    "    print(f\"Gini accuracy score\", acc_gini)\n",
    "\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth, criterion='entropy')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_preds = clf.predict(X_val)\n",
    "    acc_entropy = accuracy_score(y_val, y_preds)\n",
    "    print(f\"Entropy accuracy score\", acc_entropy)\n",
    "\n",
    "    return acc_gini, acc_entropy\n",
    "\n",
    "expe_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
